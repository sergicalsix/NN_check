{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的\n",
    "- モデルのcall関数を書き換え <- 所望の処置は無理、call関数で重みを無理やり変える\n",
    "- 自作データローダーを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shibuya/NN_check\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed = 42):\n",
    "    \n",
    "    tf.random.set_seed(seed)\n",
    "    #session_conf = tf.ConfigProto(\n",
    "    #intra_op_parallelism_threads=1,\n",
    "    #inter_op_parallelism_threads=1\n",
    "    #)\n",
    "    #sess = tf.Session(graph=tf.get_default_graph())\n",
    "    #sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    #K.set_session(sess)\n",
    "    np.random.seed(seed)\n",
    "    # for built-in random\n",
    "    random.seed(seed)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# MNISTデータを加工する\n",
    "x_train  = x_train.reshape(60000, 784)\n",
    "x_test   = x_test.reshape(10000, 784)\n",
    "x_train  = x_train.astype('float32')\n",
    "x_test   = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test  /= 255\n",
    "y_train  = keras.utils.to_categorical(y_train, 10)\n",
    "y_test   = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# MNISTデータを読込む\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\\n# MNISTデータを加工する\\nx_train  = x_train.reshape(60000, 784)\\nx_test   = x_test.reshape(10000, 784)\\nx_train  = x_train.astype(\\'float32\\')\\nx_test   = x_test.astype(\\'float32\\')\\nx_train /= 255\\nx_test  /= 255\\ny_train  = keras.utils.to_categorical(y_train, 10)\\ny_test   = keras.utils.to_categorical(y_test, 10)\\n\\n\\n\\n# モデルの構築\\ninputs = Input(shape=(784,))\\n\\nset_seed(42)\\nx = Dense(784, activation=\\'relu\\',kernel_initializer=\\'random_uniform\\', name = \"hoge\")(inputs)\\nx = Dense(100, activation=\\'relu\\',kernel_initializer=\\'random_uniform\\')(inputs)\\nx = Dense(10, activation=\\'softmax\\', kernel_initializer=\\'random_uniform\\')(x)\\n#x4 = x2 + x3\\nmodel = Model(inputs=inputs, outputs=x)\\nmodel.compile(loss=\\'categorical_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\n\\n# 学習\\nepochs = 1\\nbatch_size = 100\\nset_seed(42)\\nhistory = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\\n\\n# 検証\\nscore = model.evaluate(x_test, y_test, verbose=1)\\nprint()\\nprint(\\'Test loss:\\', score[0])\\nprint(\\'Test accuracy:\\', score[1])'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# MNISTデータを読込む\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# モデルの構築\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "set_seed(42)\n",
    "x = Dense(784, activation='relu',kernel_initializer='random_uniform', name = \"hoge\")(inputs)\n",
    "x = Dense(100, activation='relu',kernel_initializer='random_uniform')(inputs)\n",
    "x = Dense(10, activation='softmax', kernel_initializer='random_uniform')(x)\n",
    "#x4 = x2 + x3\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "epochs = 1\n",
    "batch_size = 100\n",
    "set_seed(42)\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 7s 9ms/step - loss: 0.5325 - accuracy: 0.8527 - val_loss: 0.1171 - val_accuracy: 0.9642\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.1171 - accuracy: 0.9642\n",
      "\n",
      "Test loss: 0.1170765832066536\n",
      "Test accuracy: 0.9642000198364258\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(784,))\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Define the subclassed model.\n",
    "class Model_class(Model):\n",
    "    def __init__(self):\n",
    "        super(Model_class, self).__init__()\n",
    "        set_seed(42)\n",
    "        self.layer1 = Dense(784, activation='relu',kernel_initializer='random_uniform')\n",
    "        self.layer2 = Dense(100, activation='relu',kernel_initializer='random_uniform')\n",
    "        self.layer3 = Dense(10, activation='softmax', kernel_initializer='random_uniform')\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.layer1(inputs)\n",
    "        x = self.layer2(x)\n",
    "        return self.layer3(x)\n",
    "\n",
    "model = Model_class()\n",
    "# Call model on inputs to create the variables of the dense layer.\n",
    "_ = model(inputs)\n",
    "#x4 = x2 + x3\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 100\n",
    "set_seed(42)\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 7s 11ms/step - loss: 0.5325 - accuracy: 0.8527 - val_loss: 0.1171 - val_accuracy: 0.9642\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1171 - accuracy: 0.9642: 0s - loss: 0.153\n",
      "\n",
      "Test loss: 0.1170765832066536\n",
      "Test accuracy: 0.9642000198364258\n"
     ]
    }
   ],
   "source": [
    "class Model_class(Model):\n",
    "    def __init__(self):\n",
    "        super(Model_class, self).__init__()\n",
    "        set_seed(42)\n",
    "        self.layer1 = Dense(784, activation='relu',kernel_initializer='random_uniform')\n",
    "        self.layer2 = Dense(100, activation='relu',kernel_initializer='random_uniform')\n",
    "        self.layer3 = Dense(10, activation='softmax', kernel_initializer='random_uniform')\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.layer1(inputs)\n",
    "        # うまくいかない\n",
    "        \"\"\"\n",
    "        try:\n",
    "            w,b = self.layers[2].get_weights()\n",
    "            print('hoge')\n",
    "            w[0] = 0.1\n",
    "            self.layer2.set_weight(w,b)\n",
    "        except:\n",
    "            pass\n",
    "        \"\"\"\n",
    "        x = self.layer2(x)\n",
    "        return self.layer3(x)\n",
    "\n",
    "model = Model_class()\n",
    "# Call model on inputs to create the variables of the dense layer.\n",
    "_ = model(inputs)\n",
    "#x4 = x2 + x3\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 100\n",
    "set_seed(42)\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 612ms/step - loss: 2.3012 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3085 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3012 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3102 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3160 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3213 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2969 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2942 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3059 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3118 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2937 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2985 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2823 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2878 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3038 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3121 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3202 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3000 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3133 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3045 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2959 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2848 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3075 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3028 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3059 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3056 - accuracy: 0.1800\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3297 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3027 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2978 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2867 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3039 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3104 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2996 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3033 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2991 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3073 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3024 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3091 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2948 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3044 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3115 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2847 - accuracy: 0.1800\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3043 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3042 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3110 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2965 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3034 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.2946 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.2970 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3063 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3111 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3001 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3005 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.3026 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2908 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.2974 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2938 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3091 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3053 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3017 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.3018 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2889 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3084 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2977 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3041 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3048 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3062 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3020 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3097 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2969 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2969 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2982 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3078 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3081 - accuracy: 0.0700\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3003 - accuracy: 0.13 - 0s 18ms/step - loss: 2.3003 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2993 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3024 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2993 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3071 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2880 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3031 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2968 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3030 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2941 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3035 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3117 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3080 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2987 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2991 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3082 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.3088 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2996 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2901 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3023 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.2954 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3116 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3141 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3032 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2982 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3110 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.3037 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3072 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3068 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3049 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3047 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3077 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3080 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3044 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3080 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.3023 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3030 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3056 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3008 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3012 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3039 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3029 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3059 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3052 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.2993 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3055 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2998 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2958 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3122 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2993 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3033 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3008 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3047 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3044 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3083 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2958 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3020 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2966 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3022 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2999 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3052 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3137 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2972 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3110 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3079 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3037 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3072 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3060 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3058 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2967 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3100 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2947 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2943 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3016 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3049 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3100 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3006 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3080 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3045 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2975 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2973 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3032 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2915 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3042 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3091 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2966 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2965 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3098 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.2905 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3115 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2992 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3122 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2869 - accuracy: 0.1900\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3112 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2935 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3011 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3026 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2977 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2987 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2896 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3029 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3007 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2871 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3085 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3044 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3032 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3046 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3001 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2930 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3036 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3005 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3099 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3050 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3076 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3017 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2914 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2952 - accuracy: 0.1800\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3097 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2938 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3041 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2991 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2989 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3008 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3036 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3061 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2965 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3075 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3090 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2978 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2959 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3040 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3000 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3194 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2962 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2981 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3092 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2948 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3017 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3090 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2991 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3016 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3095 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3104 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2946 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3138 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2974 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3010 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3018 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3045 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3056 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3055 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3078 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3005 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2998 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2998 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2979 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2950 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3115 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3056 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3067 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3014 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3034 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3010 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2957 - accuracy: 0.2100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2979 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2955 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2976 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2979 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3028 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3021 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3126 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3040 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3013 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3049 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3105 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3067 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2944 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3130 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3032 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3016 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3034 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2930 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3017 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3132 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3043 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3128 - accuracy: 0.0400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2910 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2987 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2990 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2965 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2941 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3041 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3032 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2965 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3131 - accuracy: 0.0400\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3082 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3035 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2965 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2989 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2965 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2996 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2977 - accuracy: 0.1900\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3075 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3138 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3020 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3025 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2968 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2937 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3101 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2942 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3070 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3110 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2979 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3022 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3050 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3014 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2885 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2971 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3122 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3020 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3015 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3059 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3121 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2953 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2995 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2963 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3010 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3002 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2983 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3016 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3047 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3078 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3033 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2988 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3005 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2998 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2942 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3009 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2997 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2902 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3067 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3005 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3019 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2939 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2891 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3067 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3043 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3131 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2950 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3128 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2933 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3095 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3077 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2871 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3079 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3131 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3081 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3038 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3018 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3085 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3017 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3055 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2901 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3012 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3040 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2994 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3070 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3047 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3104 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2994 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.3054 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2937 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3025 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2977 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3004 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3030 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3066 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3005 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3006 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3066 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2978 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3012 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2964 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3052 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3041 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2982 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2991 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2971 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3021 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3027 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3086 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3097 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2999 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2975 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3044 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3008 - accuracy: 0.0600\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3001 - accuracy: 0.13 - 0s 8ms/step - loss: 2.3001 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.3012 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3032 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2949 - accuracy: 0.1900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2958 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3064 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2940 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3061 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3009 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3107 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3069 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3077 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3029 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2958 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3087 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2990 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3007 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3060 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3001 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3017 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3038 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3022 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2944 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3080 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2972 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3034 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3008 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2984 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2991 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3055 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3019 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3041 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2949 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3035 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3027 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3057 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2925 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.2919 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2948 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3063 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3063 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2993 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3107 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3129 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3061 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2981 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.3013 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3043 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3086 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3083 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3031 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2995 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3092 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3014 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3056 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3038 - accuracy: 0.0500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2982 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3032 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2921 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3044 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3038 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2949 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3062 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3079 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2875 - accuracy: 0.2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3132 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2975 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3016 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3047 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2972 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2929 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3051 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3015 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3011 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3076 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2946 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3071 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2971 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3015 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3036 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3072 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3016 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2972 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3011 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2908 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3001 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3006 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3002 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2934 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3024 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2981 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3087 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3029 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3039 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2993 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2935 - accuracy: 0.1400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2986 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2974 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3250 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3099 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2924 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3002 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3044 - accuracy: 0.0600\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3074 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3042 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3051 - accuracy: 0.0900\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3033 - accuracy: 0.1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3042 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3010 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3120 - accuracy: 0.0400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2992 - accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2918 - accuracy: 0.1700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3016 - accuracy: 0.0700\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2937 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2980 - accuracy: 0.1600\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3033 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3040 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3051 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3081 - accuracy: 0.0800\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2967 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3028 - accuracy: 0.1100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3086 - accuracy: 0.1200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2997 - accuracy: 0.1300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2968 - accuracy: 0.1800\n"
     ]
    }
   ],
   "source": [
    "class Model_class(Model):\n",
    "    def __init__(self):\n",
    "        super(Model_class, self).__init__()\n",
    "        set_seed(42)\n",
    "        self.layer1 = Dense(784, activation='relu',kernel_initializer='random_uniform')\n",
    "        self.layer2 = Dense(100, activation='relu',kernel_initializer='random_uniform')\n",
    "        self.layer3 = Dense(10, activation='softmax', kernel_initializer='random_uniform')\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.layer1(inputs)\n",
    "        x = self.layer2(x)\n",
    "        return self.layer3(x)\n",
    "\n",
    "model = Model_class()\n",
    "# Call model on inputs to create the variables of the dense layer.\n",
    "_ = model(inputs)\n",
    "#x4 = x2 + x3\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 100\n",
    "set_seed(42)\n",
    "\n",
    "for x_,y_ in zip(x_train_loader,y_train_loader):\n",
    "    _ = model.fit(x_, y_, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_loader = data_loader(x_train,seed = 3)\n",
    "y_train_loader = data_loader(y_train,seed = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(vec, seed, batch_size=100):  # number is for mnist\n",
    "    \"\"\"\n",
    "    Example\n",
    "    mnist : 60000, 1,28,28 or 60000,784\n",
    "    cifar10: 50000,3, 32,32 or 50000,1024\n",
    "\n",
    "\n",
    "    How to:\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    np.random.shuffle(vec)\n",
    "\n",
    "    n = int(vec.shape[0]/batch_size)\n",
    "\n",
    "    size = 1\n",
    "    if vec.ndim != 1:  # 回帰問題のときは１になる\n",
    "        size = vec.shape[1]\n",
    "\n",
    "    # 画像データのとき　vec.ndim == 4\n",
    "    if vec.ndim == 4:\n",
    "        #_, channel,shape_x,shape_y= vec.shape\n",
    "        channel = vec.shape[1]\n",
    "        shape_H = vec.shape[2]\n",
    "        shape_W = vec.shape[3]\n",
    "\n",
    "        vec = vec.reshape(n, batch_size, channel, shape_H, shape_W)\n",
    "    else:\n",
    "        if size == 1:\n",
    "            vec = vec.reshape(n, batch_size)\n",
    "        else:\n",
    "            vec = vec.reshape(n, batch_size, size)\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 再現性の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01878912, -0.00155212,  0.04309944, ...,  0.02197267,\n",
       "        -0.04005278,  0.04480752],\n",
       "       [-0.00537275, -0.0163908 , -0.00531293, ..., -0.02761691,\n",
       "        -0.02099543, -0.04422212],\n",
       "       [ 0.03057282,  0.04772124,  0.0273265 , ...,  0.01920762,\n",
       "        -0.01681979,  0.04212563],\n",
       "       ...,\n",
       "       [ 0.0177031 ,  0.00048262, -0.03944298, ...,  0.0383727 ,\n",
       "        -0.01793129, -0.02333527],\n",
       "       [ 0.03191893,  0.01330081,  0.03970552, ..., -0.03449966,\n",
       "        -0.01427802,  0.02485213],\n",
       "       [-0.02796367, -0.00531797, -0.01274946, ...,  0.02140654,\n",
       "         0.00115863,  0.01362861]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()[0]  == model2.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_normal, w2_normal = model.layers[1].get_weights()[0],model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for w in w1_normal:\n",
    "#    print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
